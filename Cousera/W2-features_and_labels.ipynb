{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Preview the result\n",
    "for val in dataset:\n",
    "   print(val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Windowing the data\n",
    "\n",
    "As mentioned earlier, you want to group consecutive elements of your data and \n",
    "use that to predict a future value. \n",
    "This is called windowing and you can use that with the window() method as shown below. Here, you will take 5 elements per window (i.e. size parameter) and you will move this window 1 element at a time (i.e. shift parameter). One caveat to using this method is that each window returned is a Dataset in itself. This is a Python iterable and it won't show the elements if you use the print() method on it. It will just show a description of the data structure (e.g. <_VariantDataset shapes: (), types: tf.int64>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      "<_VariantDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data\n",
    "dataset = dataset.window(size=5, shift=1)\n",
    "\n",
    "# Print the result\n",
    "for window_dataset in dataset:\n",
    "  print(window_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[3, 4, 5, 6, 7]\n",
      "[4, 5, 6, 7, 8]\n",
      "[5, 6, 7, 8, 9]\n",
      "[6, 7, 8, 9]\n",
      "[7, 8, 9]\n",
      "[8, 9]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "for window_dataset in dataset:\n",
    "  print([item.numpy() for item in window_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[3, 4, 5, 6, 7]\n",
      "[4, 5, 6, 7, 8]\n",
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#can use the drop_remainder flag to make sure that only 5-element windows are retained.\n",
    "\n",
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data but only take those with the specified size\n",
    "dataset = dataset.window(size=5, shift=1, drop_remainder=True)\n",
    "\n",
    "# Print the result\n",
    "for window_dataset in dataset:\n",
    "  print([item.numpy() for item in window_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Flatten the Windows\n",
    "\n",
    "In training the model later, you will want to prepare the windows to be tensors instead of the Dataset structure. You can do that by feeding a mapping function to the flat_map() method. This function will be applied to each window and the results will be flattened into a single dataset. To illustrate, the code below will put all elements of a window into a single batch then flatten the result.\n",
    "\n",
    "NOTE: In the mapping function passed to flat_map(), it's important to specify the batch size to be the same size as the window (i.e. 5 in this case) so all elements will be in a single list. You can put the size manually or use the cardinality() method to detect the window size automatically. We're using the manual approach in the lectures and other exercises more often, but the other approach will also work. Try replacing 5 with window.cardinality() in the lambda function below to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[1 2 3 4 5]\n",
      "[2 3 4 5 6]\n",
      "[3 4 5 6 7]\n",
      "[4 5 6 7 8]\n",
      "[5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data but only take those with the specified size\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flatten the windows by putting its elements in a single batch\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "\n",
    "# Print the results\n",
    "for window in dataset:\n",
    "  print(window.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Group into features and labels\n",
    "\n",
    "Next, you will want to mark the labels in each window. For this exercise, you will do that by splitting the last element of each window from the first four. This is done with the map() method containing a lambda function that defines the window slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [0 1 2 3]\n",
      "y =  4\n",
      "\n",
      "x =  [1 2 3 4]\n",
      "y =  5\n",
      "\n",
      "x =  [2 3 4 5]\n",
      "y =  6\n",
      "\n",
      "x =  [3 4 5 6]\n",
      "y =  7\n",
      "\n",
      "x =  [4 5 6 7]\n",
      "y =  8\n",
      "\n",
      "x =  [5 6 7 8]\n",
      "y =  9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data but only take those with the specified size\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flatten the windows by putting its elements in a single batch\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "\n",
    "# Create tuples with features (first four elements of the window) and labels (last element)\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "# Print the results\n",
    "for x,y in dataset:\n",
    "  print(\"x = \", x.numpy())\n",
    "  print(\"y = \", y.numpy())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Shuffle the data\n",
    "\n",
    "It is good practice to shuffle your dataset to reduce sequence bias while training your model. This refers to the neural network overfitting to the order of inputs and consequently, it will not perform well when it does not see that particular order when testing. You don't want the sequence of training inputs to impact the network this way so it's good to shuffle them up.\n",
    "\n",
    "You can simply use the shuffle() method to do this. The buffer_size parameter is required for that and as mentioned in the doc, you should put a number equal or greater than the total number of elements for better shuffling. We can see from the previous cells that the total number of windows in the dataset is 6 so we can choose this number or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [5 6 7 8]\n",
      "y =  9\n",
      "\n",
      "x =  [0 1 2 3]\n",
      "y =  4\n",
      "\n",
      "x =  [3 4 5 6]\n",
      "y =  7\n",
      "\n",
      "x =  [2 3 4 5]\n",
      "y =  6\n",
      "\n",
      "x =  [4 5 6 7]\n",
      "y =  8\n",
      "\n",
      "x =  [1 2 3 4]\n",
      "y =  5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data but only take those with the specified size\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flatten the windows by putting its elements in a single batch\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "\n",
    "# Create tuples with features (first four elements of the window) and labels (last element)\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "# Shuffle the windows\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "\n",
    "# Print the results\n",
    "for x,y in dataset:\n",
    "  print(\"x = \", x.numpy())\n",
    "  print(\"y = \", y.numpy())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create batches for training\n",
    "\n",
    "Lastly, you will want to group your windows into batches. You can do that with the batch() method as shown below. Simply specify the batch size and it will return a batched dataset with that number of windows. As a rule of thumb, it is also useful to add a cache() and prefetch() step. These optimize the execution time when the model is already training.\n",
    "\n",
    "By specifying a prefetch buffer_size of 1 as shown below, Tensorflow will prepare the next one batch in advance (i.e. putting it in a buffer) while the current batch is being consumed by the model. You can read more about it here. If you've taken the first 3 courses of this Specialization, you'll know that you can also pass in a tf.data.AUTOTUNE here to let Tensorflow dynamically change this value at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[0 1 2 3]\n",
      " [3 4 5 6]]\n",
      "y =  [4 7]\n",
      "\n",
      "x =  [[5 6 7 8]\n",
      " [4 5 6 7]]\n",
      "y =  [9 8]\n",
      "\n",
      "x =  [[1 2 3 4]\n",
      " [2 3 4 5]]\n",
      "y =  [5 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a tf dataset with 10 elements (i.e. numbers 0 to 9)\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Window the data but only take those with the specified size\n",
    "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flatten the windows by putting its elements in a single batch\n",
    "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
    "\n",
    "# Create tuples with features (first four elements of the window) and labels (last element)\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "# Shuffle the windows\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "\n",
    "# Create batches of windows\n",
    "dataset = dataset.batch(2)\n",
    "\n",
    "# Optimize the dataset for training\n",
    "dataset = dataset.cache().prefetch(1)\n",
    "\n",
    "# Print the results\n",
    "for x,y in dataset:\n",
    "  print(\"x = \", x.numpy())\n",
    "  print(\"y = \", y.numpy())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
